{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adaptive Style Transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamirmal/tau_dl_proj/blob/master/Adaptive_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUJvA3lpAHZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "83d5ebca-989e-4d82-c139-91f62bd228da"
      },
      "source": [
        "!pip install ipdb\n",
        "import ipdb\n",
        "import datetime, os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision.datasets.mnist import FashionMNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# For tensorboard use TF 2.x+\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "GOOGLE_DRIVE_PATH='/content/drive/My Drive/Colab Notebooks/TAU_DL_PROJ/STYLE_TRANSFER/'\n",
        "\n",
        "exists_file_path=GOOGLE_DRIVE_PATH+'exists.file'\n",
        "if not os.path.isfile(GOOGLE_DRIVE_PATH+'exists.file'):\n",
        "  print(\"problem mounting drive FS, failed to access file {}\".format(exists_file_path))\n",
        "  assert 0\n",
        "else:\n",
        "  print(\"successfully accessed drive FS\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/df/78/3d0d7253dc85549db182cbe4b43b30c506c84008fcd39898122c9b6306a9/ipdb-0.12.2.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (41.4.0)\n",
            "Requirement already satisfied: ipython>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.4.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.7.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.3.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (1.0.18)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0->ipdb) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (1.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (0.1.7)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.12.2-cp36-none-any.whl size=9171 sha256=8ff441cfc07d5162481b8aa00b0adb2bae74888a5af4500b10b2593f92e1797d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/00/07/c906eaf1b90367fbb81bd840e56bf8859dbd3efe3838c0b4ba\n",
            "Successfully built ipdb\n",
            "Installing collected packages: ipdb\n",
            "Successfully installed ipdb-0.12.2\n",
            "TensorFlow 2.x selected.\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "successfully accessed drive FS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAHtH4w4-wJ_",
        "colab_type": "text"
      },
      "source": [
        "Implementing https://arxiv.org/pdf/1703.06868.pdf\n",
        "There is an official reference in Torch / Lua @ https://github.com/xunhuang1995/AdaIN-style/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYATh4Ri_DhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "ee39a551-9095-4fbb-8b38-10e55ff471e0"
      },
      "source": [
        "class style_transfer_net(nn.Module):\n",
        "      def __init__(self):\n",
        "        super(style_transfer_net, self).__init__()\n",
        "\n",
        "        ## using VGG as encoder/decoder\n",
        "        ## TODO : consider using other architectures as suggested in the article\n",
        "        ##        such as resnet34 etc. which are deep BUT have good convergence due to skip-connection (residuals)\n",
        "        \n",
        "        encoder_t = 'VGG19' # TODO in the future this will be external argument\n",
        "        if encoder_t == 'VGG19':\n",
        "          encoder = torchvision.models.vgg19(pretrained=True, progress=True)\n",
        "          targetContentLayer = [12]         # relu4_1\n",
        "          targetStyleLayers = [1, 4, 7, 12] # relu1_1,relu2_1,relu3_1,relu4_1\n",
        "          \n",
        "          encoder_layers = list(encoder.children())\n",
        "          # style encoders - we need to extract intermediate features from SEVERAL layers\n",
        "          # so i'm splitting the model and concatenating it in the FWD PASS\n",
        "          self.encoder_style1 = nn.Sequential(*encoder_layers[:targetStyleLayers[0]])                      # input -> relu1_1\n",
        "          self.encoder_style2 = nn.Sequential(*encoder_layers[targetStyleLayers[0]:targetStyleLayers[1]])  # relu1_1 -> relu2_1\n",
        "          self.encoder_style3 = nn.Sequential(*encoder_layers[targetStyleLayers[1]:targetStyleLayers[2]])  # relu2_1 -> relu3_1\n",
        "          self.encoder_style4 = nn.Sequential(*encoder_layers[targetStyleLayers[2]:targetStyleLayers[3]])  # relu3_1 -> relu4_1\n",
        "          # content encoder\n",
        "          self.encoder_content = nn.Sequential(*encoder_layers[18:targetStyleLayers[3]])                    # relu3_1 -> relu4_1\n",
        "\n",
        "          # Encoder IS NOT trainable - freeze it\n",
        "          for e in [encoder_style1, encoder_style_2, encoder_style_3, encoder_style_4, encoder_content]:\n",
        "              for p in e.parameters():\n",
        "                  p.requires_grad = False\n",
        "\n",
        "        decoder_t = 'VGG19'\n",
        "        if decoder_t == 'VGG19':\n",
        "          self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
        "          )\n",
        "\n",
        "      # End\n",
        "\n",
        "      def forward(self, content, style, alpha=1.0):\n",
        "        assert alpha >= 0\n",
        "        assert alpha <= 1\n",
        "\n",
        "        # TODO - add asserts that encoders are NOT trainable !!!\n",
        "\n",
        "        # FWD pass to extract style features\n",
        "        #\n",
        "        #  ENC1 --- ENC2 --- ENC3 --- ENC4 ---\n",
        "        #        |        |        |        |\n",
        "        #       feat1    feat2    feat3    feat4\n",
        "        style_features = [ style ]\n",
        "        style1 = self.encoder_style1(style)\n",
        "        style2 = self.encoder_style1(style1)\n",
        "        style3 = self.encoder_style1(style2)\n",
        "        style4 = self.encoder_style1(style3)     \n",
        "        style_features.append(style1)\n",
        "        style_features.append(style2)\n",
        "        style_features.append(style3)\n",
        "        style_features.append(style4)\n",
        "        style_features = style_features[1:]\n",
        "\n",
        "        # content features extracted from feat4 (but content is input, not style)\n",
        "        content_features = self.encoder_style1(content)\n",
        "        content_features = self.encoder_style2(content_features)\n",
        "        content_features = self.encoder_style3(content_features)\n",
        "        content_features = self.encoder_style4(content_features)\n",
        "\n",
        "      # End"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-4da98519f460>\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    def forward(self, content, style, alpha=1.0):\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvORSLClWhe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}